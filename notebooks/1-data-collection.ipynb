{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parser Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['config.ini']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import configparser\n",
    "\n",
    "file_path = 'config.ini'\n",
    "config = configparser.ConfigParser()\n",
    "config.read(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscraping Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playwright.async_api import async_playwright, Page, BrowserContext\n",
    "from tqdm.asyncio import tqdm\n",
    "\n",
    "# Define constants/webscraping parameters from config.ini\n",
    "TARGETS_URL = config['webscraping']['targets_url'].split(', ')\n",
    "IG_IFRAMES = config['webscraping']['ig_iframes'].split(', ')\n",
    "TK_IFRAMES = config['webscraping']['tk_iframes'].split(', ')\n",
    "\n",
    "# Start Playwright\n",
    "playwright = await async_playwright().start()\n",
    "browser = await playwright.chromium.launch()\n",
    "context = await browser.new_context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Exportation and Integratiy Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from IPython.display import Image, display\n",
    "import pandas as pd\n",
    "\n",
    "# Change to the parent directory to access the DFVC module\n",
    "os.chdir('..')\n",
    "from src import DFVC\n",
    "\n",
    "# Configure pandas display options for better readability\n",
    "pd.set_option('display.max_rows', None)  \n",
    "pd.set_option('display.max_columns', None) \n",
    "\n",
    "# Define constants for raw data extraction/exportation\n",
    "DB_DIR = config['database']['db_dir']\n",
    "RAW_DF_NAME = config['database']['raw_data_df_name']\n",
    "RAW_DATA_FILENAME = config['database']['raw_data_filename']\n",
    "RAW_HASH = config['database']['raw_data_version_hash']\n",
    "\n",
    "RAW_DATA_PATH = os.path.join(DB_DIR, RAW_DATA_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Webscraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Pages Reacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page reached: Instagram Revenue and Usage Statistics (2024) - Business of Apps (https://www.businessofapps.com/data/instagram-statistics/)\n",
      "Page fully loaded: Instagram Revenue and Usage Statistics (2024) - Business of Apps (https://www.businessofapps.com/data/instagram-statistics/)\n",
      "Page reached: TikTok Revenue and Usage Statistics (2024) - Business of Apps (https://www.businessofapps.com/data/tik-tok-statistics/)\n",
      "Page fully loaded: TikTok Revenue and Usage Statistics (2024) - Business of Apps (https://www.businessofapps.com/data/tik-tok-statistics/)\n"
     ]
    }
   ],
   "source": [
    "async def target_page_reacher(context: BrowserContext, TARGETS_URL: list[str]) -> tuple[Page, Page]:\n",
    "    \"\"\"\n",
    "    Opens, navigates to the research target URLs in new browser pages, and scrolls each page to the bottom.\n",
    "\n",
    "    Args:\n",
    "        context (BrowserContext): The browser context to use for opening new pages.\n",
    "        TARGETS_URL (list[str]): A list of URLs to be accessed. Assumes the list contains at least two URLs.\n",
    "\n",
    "    Returns:\n",
    "        tuple[Page, Page]: A tuple containing the two pages corresponding to the research target URLs.\n",
    "    \"\"\"\n",
    "    pages = []\n",
    "\n",
    "    for url in TARGETS_URL:\n",
    "        # Open a new page\n",
    "        page = await context.new_page()\n",
    "\n",
    "        # Navigate to the URL\n",
    "        await page.goto(url)\n",
    "        print(f\"Page reached: {await page.title()} ({url})\")\n",
    "\n",
    "        # Scroll to the bottom to ensure all content is loaded\n",
    "        scroll_height = await page.evaluate(\"() => document.body.scrollHeight\")\n",
    "        current_position = 0\n",
    "\n",
    "        while current_position < scroll_height:\n",
    "            current_position += 500  # Adjust scroll step as needed\n",
    "            await page.evaluate(f\"window.scrollTo(0, {current_position})\")\n",
    "            await page.wait_for_timeout(400)  # Wait for dynamic content to load\n",
    "            scroll_height = await page.evaluate(\"() => document.body.scrollHeight\")  # Update height if new content loads\n",
    "\n",
    "        print(f\"Page fully loaded: {await page.title()} ({url})\")\n",
    "        pages.append(page)\n",
    "\n",
    "    return pages\n",
    "\n",
    "\n",
    "ig, tk = await target_page_reacher(context, TARGETS_URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target Pages Webscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webscraping process started\n",
      "Page Title: Instagram Revenue and Usage Statistics (2024) - Business of Apps\n",
      "\n",
      "-> Starting webscraping for barchart (Instagram revenues - Infogram):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 39/39 [00:03<00:00, 12.50 Datapoint/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Completed webscraping for barchart (Instagram revenues - Infogram)\n",
      "\n",
      "-> Starting webscraping for barchart (Instagram monthly app users - Infogram):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 47/47 [00:03<00:00, 14.16 Datapoint/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Completed webscraping for barchart (Instagram monthly app users - Infogram)\n",
      "\n",
      "Webscraping process completed successfully\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Webscraping process started\n",
      "Page Title: TikTok Revenue and Usage Statistics (2024) - Business of Apps\n",
      "\n",
      "-> Starting webscraping for barchart (TikTok quarterly revenues - Infogram):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 31/31 [00:02<00:00, 13.30 Datapoint/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Completed webscraping for barchart (TikTok quarterly revenues - Infogram)\n",
      "\n",
      "-> Starting webscraping for barchart (TikTok MAUs - Infogram):\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress: 100%|██████████| 27/27 [00:01<00:00, 13.86 Datapoint/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-> Completed webscraping for barchart (TikTok MAUs - Infogram)\n",
      "\n",
      "Webscraping process completed successfully\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "async def target_pages_webscraper(page: Page, target_iframes: list[str]) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Extract specific bar chart values from the target pages within iframes.\n",
    "\n",
    "    Args:\n",
    "        page (Page): The Playwright Page object used to interact with the webpage.\n",
    "        target_iframes (list[str]): A list of iframe selectors containing the bar charts to scrape.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A DataFrame containing the extracted data with columns: \n",
    "                      'iframe_title', 'timeseries_category', and 'timeseries_value'.\n",
    "    \"\"\"\n",
    "    scraped_barchart_data = []\n",
    "\n",
    "    print('Webscraping process started')\n",
    "    print(f'Page Title: {await page.title()}')\n",
    "    print()\n",
    "\n",
    "    # Loop through each iframe containing bar chart data\n",
    "    for barchart_selector in target_iframes:\n",
    "        # Extract the title of the iframe\n",
    "        barchart_iframe_title = await page.frame_locator(barchart_selector).locator(\"title\").inner_text()\n",
    "\n",
    "        # Count the number of columns in the bar chart\n",
    "        columns_qtd = len(await page.frame_locator(barchart_selector).locator('.igc-graph .igc-column').all()) + 1\n",
    "\n",
    "        print(f'-> Starting webscraping for barchart ({barchart_iframe_title}):')\n",
    "\n",
    "        # Initialize a progress bar\n",
    "        pbar = tqdm(total=columns_qtd - 1, desc='Progress', unit=' Datapoint', leave=True)\n",
    "\n",
    "        # Extract data for each column in the bar chart\n",
    "        for i in range(1, columns_qtd):\n",
    "            await page.frame_locator(barchart_selector).locator(f'path:nth-child({i})').hover()\n",
    "\n",
    "            # Retrieve the category and value for the current column\n",
    "            target_time_series_category = await page.frame_locator(barchart_selector).locator('.tt_text').inner_text()\n",
    "            target_time_series_value = await page.frame_locator(barchart_selector).locator('.tt_value').inner_text()\n",
    "\n",
    "            # Append the extracted data to the list\n",
    "            scraped_barchart_data.append({\n",
    "                'iframe_title': barchart_iframe_title,\n",
    "                'timeseries_category': target_time_series_category,\n",
    "                'timeseries_value': target_time_series_value\n",
    "            })\n",
    "\n",
    "            # Update the progress bar\n",
    "            pbar.update(1)\n",
    "\n",
    "        # Close the progress bar and log completion for the current iframe\n",
    "        pbar.close()\n",
    "        print(f'-> Completed webscraping for barchart ({barchart_iframe_title})')\n",
    "        print()\n",
    "\n",
    "    print('Webscraping process completed successfully')\n",
    "    print('-' * 80)\n",
    "    print()\n",
    "\n",
    "    # Convert the scraped data into a pandas DataFrame\n",
    "    return pd.DataFrame(scraped_barchart_data)\n",
    "\n",
    "\n",
    "raw_data_interim = []\n",
    "raw_data_interim.append(await target_pages_webscraper(page=ig, target_iframes=IG_IFRAMES))\n",
    "raw_data_interim.append(await target_pages_webscraper(page=tk, target_iframes=TK_IFRAMES))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exportation and Integrity Verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div style='border:1px solid #1b2b30; padding:10px; border-radius:10px; width:max-content; \n",
       "                    font-family:Arial, sans-serif; background-color:#0a0e12; color:#8fa3a6; font-size:0.9em;'>\n",
       "            <div style='display: flex; align-items: center;'>\n",
       "                <button onclick=\"var info = document.getElementById('dfvc_124654993650512_info');\n",
       "                                if (info.style.display === 'none') {\n",
       "                                    info.style.display = 'block';\n",
       "                                    this.textContent = '-';\n",
       "                                } else {\n",
       "                                    info.style.display = 'none';\n",
       "                                    this.textContent = '+';\n",
       "                                }\"\n",
       "                        style='background-color:#202c31; color:#b5c9cb; border:none; padding:4px 12px; \n",
       "                            border-radius:5px; cursor:pointer; font-size:0.8em; margin-right:10px;'>\n",
       "                    +\n",
       "                </button>\n",
       "                <span style='font-weight: bold; color:#2d6f6b;'>DFVC Object</span>\n",
       "            </div>\n",
       "            <div id='dfvc_124654993650512_info' style='display:none; margin-top:10px;'>\n",
       "                <strong style='color:#2d6f6b;'>df_name==</strong>Raw Data<br>\n",
       "                <strong style='color:#2d6f6b;'>version==</strong>5cbe11afc7682723929c6216ce499a381aa486127b6997045b7d27e173ca2505<br>\n",
       "                <strong style='color:#2d6f6b;'>creation_date==</strong>2024:12:05 16:22:53 GMT+00<br>\n",
       "                <strong style='color:#2d6f6b;'>shape==</strong>(144, 3)<br>\n",
       "            </div>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<src.dfvc.DFVC at 0x715f809db350>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version integrity verified successfully.\n",
      "DFVC object successfully saved to data/1_raw.dfvc.\n"
     ]
    }
   ],
   "source": [
    "# Data preparation to export - Initialize the DFVC object with the raw data\n",
    "raw_data_interim = pd.concat(raw_data_interim)\n",
    "raw = DFVC(raw_data_interim, RAW_DF_NAME)\n",
    "display(raw)\n",
    "\n",
    "# Integrity verification\n",
    "raw.compare_versions(RAW_HASH)\n",
    "\n",
    "# At least, raw data exportation\n",
    "raw.export_as_dfvc_file(RAW_DATA_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
